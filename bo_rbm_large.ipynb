{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted Boltzmann Machine for Large Dataset (ml-latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.neural_network import BernoulliRBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of movies: 58098\n"
     ]
    }
   ],
   "source": [
    "movies = []\n",
    "\n",
    "with open('ml-latest/movies.csv', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for i, row in enumerate(reader):\n",
    "        if i != 0:\n",
    "            m_id = int(row[0])\n",
    "            movies.append(m_id)\n",
    "\n",
    "# retrieves movie index based on movie id\n",
    "m_index_lookup = {}\n",
    "            \n",
    "for i, m_id in enumerate(movies):\n",
    "    m_index_lookup[m_id] = i\n",
    "    \n",
    "n_movies = len(movies)\n",
    "print(\"# of movies:\", n_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is too large to store in memory, so we need to select a portion of the users.\n",
    "\n",
    "### Ranking users based on how many movies rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123100, 23715)\n",
      "(117490, 9279)\n",
      "(134596, 8381)\n",
      "(212343, 7884)\n",
      "(242683, 7515)\n",
      "(111908, 6645)\n",
      "(77609, 6398)\n",
      "(63783, 6346)\n",
      "(172357, 5868)\n",
      "(141955, 5810)\n"
     ]
    }
   ],
   "source": [
    "users = {}\n",
    "\n",
    "with open('ml-latest/ratings.csv', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for i, row in enumerate(reader):\n",
    "        if i != 0:\n",
    "            u_id = int(row[0])\n",
    "            if u_id not in users:\n",
    "                users[u_id] = 1\n",
    "            else:\n",
    "                users[u_id] += 1\n",
    "            \n",
    "rankings = list(users.items())\n",
    "rankings.sort(key = lambda x: x[1], reverse = True)\n",
    "for i in range(10):\n",
    "    print(rankings[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets choose the top 5000 users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "top_users = set(rankings[i][0] for i in range(5000))\n",
    "print(len(top_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading User Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users shape: (5000, 58098)\n"
     ]
    }
   ],
   "source": [
    "# 3.0 is threshold for favorable rating\n",
    "def convert_rating(rating: str):\n",
    "    r = float(rating)\n",
    "    if (r < 3.0):\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "users = np.full((5000, n_movies), -1, dtype=np.int8)\n",
    "\n",
    "curr_id = 0\n",
    "index = 0\n",
    "\n",
    "with open('ml-latest/ratings.csv', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for i, row in enumerate(reader):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        \n",
    "        u_id = int(row[0])\n",
    "        if u_id not in top_users:\n",
    "            continue\n",
    "            \n",
    "        if curr_id == 0:\n",
    "            curr_id = u_id\n",
    "        elif u_id != curr_id:\n",
    "            index += 1\n",
    "            curr_id = u_id\n",
    "        m_id = int(row[1])\n",
    "        m_index = m_index_lookup[m_id]\n",
    "        m_rating = convert_rating(row[2])\n",
    "        users[index][m_index] = m_rating\n",
    "\n",
    "print(\"users shape:\", users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average # ratings per user: 1237.9444\n"
     ]
    }
   ],
   "source": [
    "def average_ratings_per_user(users):\n",
    "    total = 0\n",
    "    for user in users:\n",
    "        # element-wise addition\n",
    "        arr = user + 1\n",
    "        # numpy has an advanced feature called Boolean Array Indexing\n",
    "        # sets each element in arr that is greater than 0 to 1\n",
    "        arr[arr > 0] = 1\n",
    "        total += np.sum(arr)\n",
    "    print(\"average # ratings per user:\", total / len(users))\n",
    "    \n",
    "average_ratings_per_user(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_rows(arr, col=0):\n",
    "    return arr[np.argsort(arr[:, col])]\n",
    "\n",
    "# selects k rows with the highest # of ratings\n",
    "# TODO: update movie index\n",
    "def filter(arr, k):\n",
    "    arr2 = np.copy(arr)\n",
    "    arr2 += 1\n",
    "    arr2[arr2 > 0] = 1\n",
    "    sums = np.empty((arr2.shape[0], 2))\n",
    "    for i, row in enumerate(arr2):\n",
    "        sums[i, 0] = np.sum(row)\n",
    "        sums[i, 1] = i\n",
    "    sums = sort_rows(sums)\n",
    "    sums = sums[::-1] # reverse array\n",
    "#     for i in range(k):\n",
    "#         print(sums[i])\n",
    "    indices = sums[:k, 1].T.astype(int)\n",
    "    indices = np.sort(indices)\n",
    "#     print(indices)\n",
    "    top_k = arr[indices]\n",
    "#     print(top_k.shape)\n",
    "    return top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 5000)\n",
      "average # ratings per user: 1030.5642\n"
     ]
    }
   ],
   "source": [
    "users2 = filter(users.T, 5000).T\n",
    "print(users2.shape)\n",
    "average_ratings_per_user(users2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPUTE_MODE = \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some users are tough reviewers; others are more forgiving\n",
    "# This function will randomly assign 1s and 0s based on their current review probabilities\n",
    "def impute_missing(X, mode=\"default\"):\n",
    "    if mode == \"default\":\n",
    "        for i, row in enumerate(X):\n",
    "            # calculate how likely the user will give\n",
    "            # a posive review\n",
    "            neg = np.sum(row == 0)\n",
    "            pos = np.sum(row == 1)\n",
    "            p = pos / (pos + neg)\n",
    "\n",
    "            missing = row == -1\n",
    "            imputed = np.random.rand(np.sum(missing))\n",
    "            imputed = imputed < p\n",
    "            row[missing] = imputed.astype(int)\n",
    "            \n",
    "    elif mode == \"random\":\n",
    "        for row in X:\n",
    "            missing = row == -1\n",
    "            imputed = np.random.rand(np.sum(missing))\n",
    "            imputed = imputed < 0.5\n",
    "            row[missing] = imputed.astype(int)\n",
    "            \n",
    "    elif mode == \"zero\":\n",
    "        X[X < 0] = 0\n",
    "        \n",
    "def split_data(data, mode=\"default\"):\n",
    "    pi = np.random.permutation(data.shape[0])\n",
    "    split = int(data.shape[0] * 0.8)\n",
    "\n",
    "    Xtr_missing = data[pi[:split], :]\n",
    "    Xte_missing = data[pi[split:], :]\n",
    "\n",
    "    Xtr, Xte = np.copy(Xtr_missing), np.copy(Xte_missing)\n",
    "\n",
    "    # Imputing Missing Values\n",
    "    impute_missing(Xtr, mode)\n",
    "    impute_missing(Xte, mode)\n",
    "    \n",
    "    return Xtr, Xte, Xtr_missing, Xte_missing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training shape: (4000, 5000)\n",
      "testing shape: (1000, 5000)\n"
     ]
    }
   ],
   "source": [
    "Xtr, Xte, Xtr_missing, Xte_missing = split_data(users2, mode=IMPUTE_MODE)\n",
    "\n",
    "print(\"training shape:\", Xtr.shape)\n",
    "print(\"testing shape:\", Xte.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free up memory!\n",
    "users = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBM Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliRBM(batch_size=10, learning_rate=0.01, n_components=256, n_iter=100,\n",
       "             random_state=0, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbm = BernoulliRBM(\n",
    "    n_components = 256,\n",
    "    learning_rate = 0.01,\n",
    "    batch_size = 10,\n",
    "    n_iter = 100,\n",
    "    verbose = 0,\n",
    "    random_state = 0\n",
    ")\n",
    "\n",
    "# this might take an hour or 2\n",
    "rbm.fit(Xtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2656.4689415270454\n"
     ]
    }
   ],
   "source": [
    "# is this good or bad?\n",
    "print(rbm.score_samples(Xte).mean())\n",
    "\n",
    "# -3074.7298431236204\n",
    "# BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=100, n_iter=100,\n",
    "#            random_state=0, verbose=0)\n",
    "\n",
    "# -2615.214292444867\n",
    "# BernoulliRBM(batch_size=10, learning_rate=0.01, n_components=256, n_iter=100,\n",
    "#             random_state=0, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conceal_ratings(data, portion=0.3):\n",
    "    # create mask marking all known ratings\n",
    "    mask = data + 1\n",
    "    mask[mask > 0] = 1\n",
    "\n",
    "    concealed = np.copy(data)\n",
    "    for user, mask_row in zip(concealed, mask):\n",
    "        indices = mask_row.nonzero()[0]\n",
    "        n_ratings = indices.shape[0]\n",
    "        indices = np.random.permutation(indices)\n",
    "        split = int(n_ratings * portion)\n",
    "        # set 30% of known ratings to missing\n",
    "        user[indices[:split]] = -1\n",
    "        # turn off bits for the latter 70% part of the mask\n",
    "        mask_row[indices[split:]] = 0\n",
    "        \n",
    "    return concealed, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw prediction\n",
    "\n",
    "def sample_missing(rbm, Xobs, n_iters=10, mode=\"default\"):\n",
    "    Xhat = np.copy(Xobs)\n",
    "    # impute missing values\n",
    "    impute_missing(Xhat, mode)\n",
    "    # print(\"preprocess done\")\n",
    "    for i in range(n_iters):\n",
    "        Xhat = rbm.gibbs(Xhat).astype(int)\n",
    "        Xhat[Xobs >= 0] = Xobs[Xobs >= 0]\n",
    "    return Xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average prediction\n",
    "\n",
    "def sample_missing(rbm, Xobs, n_iters=10, mode=\"default\"):\n",
    "    Xhat = np.copy(Xobs)\n",
    "    # impute missing values\n",
    "    impute_missing(Xhat, mode)\n",
    "    # print(\"preprocess done\")\n",
    "    avg_xhat = []\n",
    "    for i in range(n_iters):\n",
    "        Xhat = rbm.gibbs(Xhat).astype(int)\n",
    "        Xhat[Xobs >= 0] = Xobs[Xobs >= 0]\n",
    "        avg_xhat.append(Xhat)\n",
    "    mean_score = np.mean(avg_xhat, axis=0)\n",
    "    mean_score[mean_score>0.5] = int(1) \n",
    "    mean_score[mean_score<=0.5] = int(0)\n",
    "    return mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte_concealed, mask = conceal_ratings(Xte_missing, 0.3)\n",
    "\n",
    "# Xte_concealed will now be same as Xte_missing \n",
    "    #   but with 30% of known ratings concealed.\n",
    "    # mask will mark the locations of all ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte_predict = sample_missing(rbm, Xte_concealed, n_iters = 100, mode = IMPUTE_MODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: 101315\n",
      "Total Checks: 306403\n",
      "Error Rate: 0.3306592951113403\n",
      "RMSE: 0.5750298210626474\n"
     ]
    }
   ],
   "source": [
    "num_checks = np.sum(mask)\n",
    "arr1 = Xte_missing * mask\n",
    "arr2 = Xte_predict * mask\n",
    "arr2 = arr2.astype(np.int8)\n",
    "result = arr1 ^ arr2\n",
    "num_err = np.sum(result)\n",
    "\n",
    "print(\"Errors:\", num_err)\n",
    "print(\"Total Checks:\", num_checks)\n",
    "print(\"Error Rate:\", num_err / num_checks)\n",
    "print(\"RMSE:\", np.sqrt(num_err/num_checks))\n",
    "\n",
    "# before calcuting average\n",
    "\n",
    "#Errors: 101246\n",
    "#Total Checks: 306403\n",
    "#Error Rate: 0.3304341014937843\n",
    "#RMSE: 0.5748339773306588\n",
    "\n",
    "\n",
    "# after calcuting average\n",
    "\n",
    "#Errors: 70769\n",
    "#Total Checks: 306403\n",
    "#Error Rate: 0.2309670597220001\n",
    "#RMSE: 0.4805903242076354"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives:  180199\n",
      "True Negatives:  25071\n",
      "False Positives: 49476\n",
      "False Negatives: 51657\n",
      "\n",
      "Accuracy:  0.6699346938509088\n",
      "Precision: 0.7845825623163165\n",
      "Recall:    0.7772022289697054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'True Positives:  232206\\nTrue Negatives:  7664\\nFalse Positives: 65181\\nFalse Negatives: 5951\\n\\nAccuracy:  0.7712812136256358\\nPrecision: 0.7808209504786692\\nRecall:    0.9750122818140974\\n\\nTrue Positives:  223820\\nTrue Negatives:  11814\\nFalse Positives: 62733\\nFalse Negatives: 8036\\n\\nAccuracy:  0.7690329402779998\\nPrecision: 0.7810771480319522\\nRecall:    0.9653405562073011'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1_b = arr1.astype(bool)\n",
    "arr2_b = arr2.astype(bool)\n",
    "\n",
    "# false positive:\n",
    "fp_arr = np.invert(arr1_b) & arr2_b\n",
    "# false negative:\n",
    "fn_arr = arr1_b & np.invert(arr2_b)\n",
    "# true positive:\n",
    "tp_arr = arr1_b & arr2_b\n",
    "\n",
    "fp = np.sum(fp_arr)\n",
    "fn = np.sum(fn_arr)\n",
    "tp = np.sum(tp_arr)\n",
    "# since we're checking only a handful of indices\n",
    "# true negative has to be calculated from the 3 other values\n",
    "tn = num_checks - (fp + fn + tp)\n",
    "\n",
    "print(\"True Positives: \", tp)\n",
    "print(\"True Negatives: \", tn)\n",
    "print(\"False Positives:\", fp)\n",
    "print(\"False Negatives:\", fn)\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "\n",
    "print()\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:   \", recall)\n",
    "\n",
    "#raw prediction\n",
    "#True Positives:  180303\n",
    "#True Negatives:  24854\n",
    "#False Positives: 49693\n",
    "#False Negatives: 51553\n",
    "\n",
    "#Accuracy:  0.6695658985062156\n",
    "#Precision: 0.7839397206907947\n",
    "#Recall:    0.7776507832447727'''\n",
    "\n",
    "# average prediction\n",
    "\n",
    "#True Positives:  223820\n",
    "#True Negatives:  11814\n",
    "#False Positives: 62733\n",
    "#False Negatives: 8036\n",
    "\n",
    "#Accuracy:  0.7690329402779998\n",
    "#Precision: 0.7810771480319522\n",
    "#Recall:    0.9653405562073011'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more metrics from sklearn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score:  0.8837323692296137\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC score: \", roc_auc_score(y_true=arr1, y_score=arr2, average=\"micro\"))\n",
    "\n",
    "# 0.8837323692296137   raw prediction\n",
    "# 0.9759114328658953   average prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
